{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing numpy and python is a prerequisite to knowing tensorflow and pytorch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Concepts in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dynamically Typed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5 # Type is determined at runtime\n",
    "x = 'hello' # You can even change the type of a variable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Built-in data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [1, 2, 3, 'hello'] # lists store multiple of values indexed by [0, 1, 2, ...]\n",
    "print('List value at index 2: ', x[2])\n",
    "dc = {'a': 0, 'b': 1, 'c': 2, 'd': 'hello'} # dictionaries store key value pairs\n",
    "print('Dictionary value at key \"c\": ', dc['c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mutability vs. Immutability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [1, 2, 3, 'hello'] # lists are mutable. That means you can change the values inside a list\n",
    "ls[2] = 'world'\n",
    "print(ls)\n",
    "tp = (1, 2, 3, 'hello') # tuples are immutable lists. What does that mean?\n",
    "try:\n",
    "    tp[0] = 'world'\n",
    "except TypeError:\n",
    "    print('Tuple assignment failed!')\n",
    "print(tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Arrays (Tensors)\n",
    "Numpy arrays are an N-dimensional table of values, otherwise known as tensors in mathematics. You have probably seen tensors in college/high school under a different name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vector is a 1d tensor\n",
    "a = np.array([4, 5, 6])\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "print('Vector addition: ', a+b)\n",
    "print('Scalar multiplication: ', 3*a)\n",
    "print('Elementwise multiplication: ', a*b)\n",
    "print('Inner (Dot) Product: ', a@b)\n",
    "print('Shape of a: ', a.shape)\n",
    "print('Value of a at index 0: ', a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A matrix is a 2d tensor\n",
    "A = np.array([\n",
    "    [1, 0, 0], \n",
    "    [0, 1, 0], \n",
    "    [0, 0, 1]\n",
    "])\n",
    "B = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6], \n",
    "    [7, 8, 9]\n",
    "])\n",
    "print('Matrix addition: \\n', A+B)\n",
    "print('Elementwise multiplication: ', A*B)\n",
    "print('Matrix multiplication: \\n', A@B)\n",
    "print('Shape of A: ', A.shape)\n",
    "print('Value of A at index 0, 1: ', A[0, 1])\n",
    "print('Row 1 of A', A[1, :])\n",
    "print('Column 0 of A: ', A[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Operations\n",
    "Suppose we want to sum or take the mean along rows and columns of a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6], \n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "print('Total sum: ', np.sum(B))\n",
    "print('Row sums: ', np.sum(B, axis=0)) # Sum over the row axis\n",
    "\n",
    "# TODO: Suppose we want to take the mean over columns. Use np.mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "In linear algebra, you learned that matrix addition can only occur between matrices of the same size. This is not true in numpy. You can add tensors of different sizes and even dimensions.\n",
    "\n",
    "Two axes are compatible if:\n",
    "1. They are equal\n",
    "2. One axis is 1\n",
    "\n",
    "If we are adding two numpy arrays with unequal dimensions, the array with the smaller dimension has 1's prepended. \n",
    "\n",
    "Two numpy arrays can be added, subtracted, multiplied, etc ... if all axes are compatible between the two arrays. \n",
    "Determine if matrices with the following shapes are compatible: \n",
    "* (28, 28, 3) + (3,)\n",
    "* (28, 28, 3) + (28)\n",
    "* (28, 28, 3) + (28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: (3, 3) + (3) \n",
    "A = np.array([\n",
    "    [1, 0, 0], \n",
    "    [0, 1, 0], \n",
    "    [0, 0, 1]\n",
    "])\n",
    "a = np.array([4, 5, 6])\n",
    "print('Matrix-vector addition 1: \\n', A + a)\n",
    "\n",
    "# TODO: Implement method to add a to columns of A instead. Use np.expand_dims \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors Classifier\n",
    "For later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train_data = np.random.random((50,2))\n",
    "train_labels = (train_data[:, 0] + train_data[:, 1]) > 1\n",
    "plt.scatter(train_data[:, 0], train_data[:, 1], c=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighbors():\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.train_labels = None\n",
    "    \n",
    "    def fit(self, train_data, train_labels):\n",
    "        '''\n",
    "        train_data is shape (N, D) where N is the number of data points and D is the dimension of each data point. \n",
    "        '''\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "    \n",
    "    def predict(self, data, algorithm = 'naive'):\n",
    "        '''\n",
    "        data is shape (M, D) where M is the number of data points and D is the dimension of each data point\n",
    "        '''\n",
    "        if algorithm == 'naive':\n",
    "            dist_matrix = self._get_dist_matrix_naive(data)\n",
    "        elif algorithm == 'one-loop':\n",
    "            dist_matrix = self._get_dist_matrix(data)\n",
    "        else:\n",
    "            raise ValueError('algorithm input not understood')\n",
    "        argmin = np.argmin(dist_matrix, axis=0)\n",
    "        return self.train_labels[argmin]\n",
    "    \n",
    "    def _get_dist_matrix_naive(self, data):\n",
    "        '''\n",
    "        data is shape (M, D) where M is the number of data points and D is the dimension of each data point\n",
    "        return a matrix of shape (N, M) where the ith jth element is the distance between self.train[i] and\n",
    "        data[j]\n",
    "        '''\n",
    "        dist = np.empty((self.train_data.shape[0], data.shape[0]))\n",
    "        for i in range(self.train_data.shape[0]):\n",
    "            for j in range(data.shape[0]):\n",
    "                dist[i, j] = np.mean((self.train_data[i] - data[j])**2)\n",
    "        return dist\n",
    "    \n",
    "    def _get_dist_matrix(self, data):\n",
    "        '''\n",
    "        data is shape (M, D) where M is the number of data points and D is the dimension of each data point\n",
    "        return a matrix of shape (N, M) where the ith jth element is the distance between self.train[i] and\n",
    "        data[j]\n",
    "        '''\n",
    "        dist = np.empty((self.train_data.shape[0], data.shape[0]))\n",
    "        # TODO: Implement one loop algorithm \n",
    "        return dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.random.random((50, 2))\n",
    "plt.scatter(train_data[:, 0], train_data[:, 1], c=train_labels)\n",
    "plt.scatter(test_data[:, 0], test_data[:, 1], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NearestNeighbors()\n",
    "nn.fit(train_data, train_labels)\n",
    "test_labels = nn.predict(test_data)\n",
    "plt.scatter(train_data[:, 0], train_data[:, 1], c=train_labels)\n",
    "plt.scatter(test_data[:, 0], test_data[:, 1], c=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_labels = nn.predict(test_data)\n",
    "end = time.time()\n",
    "print('Naive Implementation Time: ', end - start)\n",
    "start = time.time()\n",
    "test_labels = nn.predict(test_data, algorithm='one-loop')\n",
    "end = time.time()\n",
    "print('One Loop Implementation Time: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
